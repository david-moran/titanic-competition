{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for\n",
    "https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Competition Description\n",
    "===================\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal\n",
    "====\n",
    "\n",
    "It is your job to predict if a passenger survived the sinking of the Titanic or not.\n",
    "For each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.\n",
    "Metric\n",
    "\n",
    "Your score is the percentage of passengers you correctly predict. This is known simply as \"accuracy‚Äù.\n",
    "Submission File Format\n",
    "\n",
    "You should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\n",
    "\n",
    "The file should have exactly 2 columns:\n",
    "\n",
    "* PassengerId (sorted in any order)\n",
    "* Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "d821747c-0174-4a18-ad99-7112072c2dfc",
    "_uuid": "36aff20eae85552d4ca5c8fedab490c13b6e3967",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e6a721f3-ae14-4217-bf4f-abb384e2d03d",
    "_uuid": "5daaa6a97c2f867359ed411f0f14fba3912c2650",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dataset = pd.read_csv('train.csv')\n",
    "titanic_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "14badf2e-4a58-4a19-aae0-f9785c3707a0",
    "_uuid": "61c76b68c8b390db53be3071ece4c1c2f89e154c"
   },
   "source": [
    "Prepare the data\n",
    "========\n",
    "\n",
    "* One hot encode Sex and Embarked variables \n",
    "* Removed features do not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "f319f7f1-0e1c-40c2-af2e-3b9113dc5d17",
    "_uuid": "ac295fa24e789c92ddd85e6b86df4ab160ccba2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500           0         1   \n",
       "1         1       1  38.0      1      0  71.2833           1         0   \n",
       "2         1       3  26.0      0      0   7.9250           1         0   \n",
       "3         1       1  35.0      1      0  53.1000           1         0   \n",
       "4         0       3  35.0      0      0   8.0500           0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(titanic_dataset[['Sex', 'Embarked']])\n",
    "titanic_dataset = pd.concat([titanic_dataset, dummies], axis=1)\n",
    "titanic_dataset = titanic_dataset.drop(\n",
    "    ['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "\n",
    "titanic_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75a62190-376c-4a1a-bf11-301056600341",
    "_uuid": "c6a012656fd233c38280ed4a890d64bf119238b4"
   },
   "source": [
    "Convert dataset to numpy array\n",
    "==============\n",
    "\n",
    "* Move target labes to last column\n",
    "* Convert the dataset to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "0ee72012-f254-49a3-9a43-dce29ffa98bf",
    "_uuid": "12b97609311c8f406e663ee598fd499199fa8ab7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Embarked_C  Embarked_Q  Embarked_S     Fare  Parch  Pclass  \\\n",
       "0  22.0           0           0           1   7.2500      0       3   \n",
       "1  38.0           1           0           0  71.2833      0       1   \n",
       "2  26.0           0           0           1   7.9250      0       3   \n",
       "3  35.0           0           0           1  53.1000      0       1   \n",
       "4  35.0           0           0           1   8.0500      0       3   \n",
       "\n",
       "   Sex_female  Sex_male  SibSp  Survived  \n",
       "0           0         1      1         0  \n",
       "1           1         0      1         1  \n",
       "2           1         0      0         1  \n",
       "3           1         0      1         1  \n",
       "4           0         1      0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dataset = titanic_dataset[[c for c in sorted(titanic_dataset) if c != 'Survived'] + ['Survived']]\n",
    "titanic_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "8ea74963-c6fe-42cc-8485-807d430abf91",
    "_uuid": "29728b5d0842dd111131bcff782d8c9f16a06f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_max_min = {}\n",
    "\n",
    "# Convert to numpy array\n",
    "titanic_np = np.array(titanic_dataset)\n",
    "\n",
    "# Remove NaN values\n",
    "titanic_np[np.isnan(titanic_np)] = -1\n",
    "rows, columns = titanic_np.shape\n",
    "\n",
    "# Normalize each column\n",
    "for i in range(columns - 1):\n",
    "    column = titanic_np[:, i]\n",
    "    _min, _max = column.min(), column.max()\n",
    "    \n",
    "    # Store max and min values to normalize testing values\n",
    "    columns_max_min[i] = {'max': _max, 'min': _min}\n",
    "    \n",
    "    titanic_np[:, i] = (column - _min) / _max\n",
    "    \n",
    "titanic_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2aa772fd-9d15-42e2-b328-3d7ec7f60f0c",
    "_uuid": "84a405ccdb5e08be6b61ffb4003fe24b0834a1fd"
   },
   "source": [
    "Prepare the model\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "afa592ef-e6f2-4869-9575-cf905bdb5e53",
    "_uuid": "8bd6248fb1ff9cc448acc1cbe54be1ed801653ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_placeholders():\n",
    "    \"\"\"\n",
    "    Return a tuple with model placeholders.\n",
    "    \n",
    "    Returns (inputs, labels, keep_prob) =>\n",
    "        inputs: represent the input batches\n",
    "        labels: represet the real outputs for a given inputs\n",
    "        keep_prob: It's the probability to mantain a unit output for each label\n",
    "    \"\"\"\n",
    "    inputs = tf.placeholder(tf.float32, shape=(None, columns - 1), name='inputs')\n",
    "    labels = tf.placeholder(tf.int32, shape=(None, 1), name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, labels, keep_prob\n",
    "\n",
    "def fully_connected(input_tensor, output_dim, activation, name):\n",
    "    \"\"\"\n",
    "    Return a fully connected layer\n",
    "        input_tensor => The input for this layer.\n",
    "        output_dim => Unit number of this layer.\n",
    "        activation => Activation function for this layer\n",
    "        name => Name of the layer.\n",
    "        \n",
    "        Returns a tensor representing the fully connected layer output.\n",
    "    \"\"\"\n",
    "    input_dim = input_tensor.get_shape()[-1].value\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal(shape=(input_dim, output_dim),\n",
    "                                                                    stddev=1 / np.sqrt(input_dim)),\n",
    "                                 name='weights')\n",
    "        \n",
    "        output = tf.matmul(input_tensor, w)\n",
    "        b = tf.Variable(tf.zeros(output_dim),\n",
    "                                 name='bias')\n",
    "        \n",
    "        output = tf.nn.bias_add(tf.matmul(input_tensor, w), b,\n",
    "                                                name='logits')\n",
    "\n",
    "        tf.summary.histogram('{}_weights'.format(name), w)\n",
    "        tf.summary.histogram('{}_bias'.format(name), b)\n",
    "        \n",
    "        if activation is not None:\n",
    "            return activation(output, name='output')\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "def build_model(reuse=False):\n",
    "    \"\"\"\n",
    "    Build a NN model based only in fully connected layers.\n",
    "    \n",
    "    Returns a namedtuple with following keys:\n",
    "        inputs => placeholder representing input batches\n",
    "        labels => placeholder holding expected values\n",
    "        keep_prob => Probabilities of mantain the output for hidden units\n",
    "        output => The model output\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('model', reuse=reuse):\n",
    "        inputs, labels, keep_prob = get_placeholders()\n",
    "\n",
    "        layer1 = fully_connected(inputs, 128, tf.nn.relu, 'layer1')\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob)\n",
    "\n",
    "        layer2 = fully_connected(layer1, 64, tf.nn.relu, 'layer2')\n",
    "        layer2 = tf.nn.dropout(layer2, keep_prob)\n",
    "\n",
    "        layer3 = fully_connected(layer2, 32, tf.nn.relu, 'layer3')\n",
    "        layer3 = tf.nn.dropout(layer3, keep_prob)\n",
    "\n",
    "        output = fully_connected(layer3, 1, tf.nn.sigmoid, 'output')\n",
    "\n",
    "        Model = namedtuple('Model', ['inputs', 'labels', 'keep_prob', 'output'])\n",
    "\n",
    "        return Model(inputs=inputs, labels=labels, keep_prob=keep_prob, output=output)\n",
    "\n",
    "\n",
    "def get_loss(output, labels):\n",
    "    \"\"\"\n",
    "    Return MSE given the model output and expected categories.\n",
    "    \n",
    "    output => Model output\n",
    "    labels => Expected values.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('loss'):\n",
    "        loss = tf.losses.mean_squared_error(output, labels)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def get_optimizer(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Return AdapOptimizer optimizer.\n",
    "    \n",
    "    loss => tensor representing a cost function of a model\n",
    "    learning_rate => A tensor or a float holding learning_rate hyperparameter.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('optimizer'):\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            return tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "def get_accuracy(output, labels):\n",
    "    \"\"\"\n",
    "    Return the accuracy given outputs and labels\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('accuracy'):\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(tf.round(output), tf.cast(labels, tf.float32)), tf.float32))\n",
    "        tf.summary.scalar('accuracy', acc)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cbbb1033d795088f6f1f7eef81ef36ffadba298c"
   },
   "source": [
    "Get batches\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "539452bd-f16f-45db-81c4-68ee7d8b4218",
    "_uuid": "28253780331af1ca3bfa95f0bd85b21ea087bf3a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_validation(dataset, validation_split = 0.05):\n",
    "    \"\"\"\n",
    "    Split into training and validation set\n",
    "        dataset => dataset to split\n",
    "        validation_split => Multiplier determining how many elements will have the validation set\n",
    "    \n",
    "    Returns a namedtuple with following keys:\n",
    "        training_x => All inputs\n",
    "        training_y => All expected outputs for train_x\n",
    "        validation_x => Inputs not used for training\n",
    "        validation_y => All expected outputs for val_x\n",
    "    \"\"\"\n",
    "    validation_start = int(len(dataset) * validation_split)\n",
    "    training_x, training_y = dataset[:-validation_start, :-1], dataset[:-validation_start, -1]\n",
    "    validation_x, validation_y = dataset[-validation_start:, :-1], dataset[-validation_start:, -1]\n",
    "    \n",
    "    Batch = namedtuple('Batch', ['training_x', 'training_y', 'validation_x', 'validation_y'])\n",
    "    \n",
    "    return Batch(training_x=training_x, training_y=training_y, validation_x=validation_x, validation_y=validation_y)\n",
    "\n",
    "\n",
    "def get_batches(x, y, batch_size):\n",
    "    \"\"\"\n",
    "    Generator wich yield each batch\n",
    "    \n",
    "    x => Inputs\n",
    "    y => Expected outputs (labels)\n",
    "    batch_size => Number of elements in a batch during the training phase\n",
    "    \n",
    "    Returns a tuple of size batch_size.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(len(x) == len(y))\n",
    "    \n",
    "    for i in range(0, len(x), batch_size):\n",
    "        yield x[i:i+batch_size], y[i:i+batch_size].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "508fe73cf3f81a1f79e32b3d6dd028e7f1973342",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "keep_prob = 0.8\n",
    "\n",
    "print_every_steps=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b3ea399ee74d81c61ce10837b64225e5efe43a6d"
   },
   "outputs": [],
   "source": [
    "# Reset default model\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Get model, loss and optimizer\n",
    "model = build_model()\n",
    "loss = get_loss(model.output, model.labels)\n",
    "optimizer = get_optimizer(loss, learning_rate)\n",
    "accuracy = get_accuracy(model.output, model.labels)\n",
    "\n",
    "# Get variable summarizer\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Split into training and validation sets\n",
    "dataset = split_validation(titanic_np, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "103f962c-64f5-442d-8af8-cf49de6b5cab",
    "_uuid": "1356695cbd0f81720918ef58a41eae5e417cb515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20. train. loss: 0.1853 train. acc: 0.7462 val loss: 0.1284 val. acc: 0.8056\n",
      "Epoch  3/20. train. loss: 0.1689 train. acc: 0.7733 val loss: 0.1127 val. acc: 0.8333\n",
      "Epoch  5/20. train. loss: 0.1621 train. acc: 0.7830 val loss: 0.1064 val. acc: 0.8611\n",
      "Epoch  7/20. train. loss: 0.1584 train. acc: 0.7881 val loss: 0.1035 val. acc: 0.8681\n",
      "Epoch  9/20. train. loss: 0.1553 train. acc: 0.7917 val loss: 0.1022 val. acc: 0.8681\n",
      "Epoch 11/20. train. loss: 0.1529 train. acc: 0.7941 val loss: 0.1011 val. acc: 0.8681\n",
      "Epoch 13/20. train. loss: 0.1508 train. acc: 0.7975 val loss: 0.1056 val. acc: 0.8333\n",
      "Epoch 15/20. train. loss: 0.1495 train. acc: 0.7990 val loss: 0.1049 val. acc: 0.8889\n",
      "Epoch 16/20. train. loss: 0.1482 train. acc: 0.8003 val loss: 0.1024 val. acc: 0.8681\n",
      "Epoch 18/20. train. loss: 0.1474 train. acc: 0.8017 val loss: 0.1016 val. acc: 0.8681\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "validation_steps = 0\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    \n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in get_batches(dataset.training_x, dataset.training_y, batch_size):\n",
    "            # Run training step\n",
    "            feed_dict = {\n",
    "                model.inputs: batch_x,\n",
    "                model.labels: batch_y,\n",
    "                model.keep_prob: keep_prob}\n",
    "            summary, loss_val, acc_val, _ = sess.run([merged, loss, accuracy, optimizer], feed_dict=feed_dict)\n",
    "            training_loss.append(loss_val)\n",
    "            training_accuracy.append(acc_val)\n",
    "\n",
    "            # Write tensorflow summary for tensorboard\n",
    "            train_writer.add_summary(summary, steps)\n",
    "            steps += 1\n",
    "\n",
    "            if steps % print_every_steps == 0:\n",
    "                validation_loss = []\n",
    "                validation_accuracy = []\n",
    "\n",
    "                for val_x, val_y in get_batches(dataset.validation_x, dataset.validation_y, batch_size):\n",
    "                    # Run a validation step\n",
    "                    feed_dict = {\n",
    "                        model.inputs: val_x,\n",
    "                        model.labels: val_y,\n",
    "                        model.keep_prob: 1}\n",
    "                    summary, loss_val, acc_val = sess.run([merged, loss, accuracy], feed_dict=feed_dict)\n",
    "                    validation_loss.append(loss_val)\n",
    "                    validation_accuracy.append(acc_val)\n",
    "\n",
    "                    validation_steps += 1\n",
    "\n",
    "                print('Epoch {:2}/{:02}. train. loss: {:01.4f} train. acc: {:01.4f} val loss: {:01.4f} val. acc: {:01.4f}'.format(\n",
    "                    epoch, epochs,\n",
    "                    np.mean(training_loss), np.mean(training_accuracy),\n",
    "                    np.mean(validation_loss), np.mean(validation_accuracy)))\n",
    "    saver.save(sess, 'model/titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test data\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('test.csv')\n",
    "\n",
    "dummies = pd.get_dummies(titanic_test[['Sex', 'Embarked']])\n",
    "titanic_test = pd.concat([titanic_test, dummies], axis=1)\n",
    "titanic_test = titanic_test.drop(\n",
    "    ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "\n",
    "titanic_test = titanic_test[[c for c in sorted(titanic_test) if c != 'PassengerId'] + ['PassengerId']]\n",
    "\n",
    "# Convert to numpy array\n",
    "titanic_test_np = np.array(titanic_test)\n",
    "\n",
    "# Remove NaN values\n",
    "titanic_test_np[np.isnan(titanic_test_np)] = -1\n",
    "rows, columns = titanic_test_np.shape\n",
    "\n",
    "# Normalize each column\n",
    "for i in range(columns - 1):\n",
    "    column = titanic_test_np[:, i]\n",
    "    _min, _max = columns_max_min[i]['min'], columns_max_min[i]['max']\n",
    "    titanic_test_np[:, i] = (column - _min) / _max\n",
    "\n",
    "titanic_test_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/titanic\n"
     ]
    }
   ],
   "source": [
    "with open('submission.csv', 'w') as fd:\n",
    "    fd.write('PassengerId,Survived\\n')\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, 'model/titanic')\n",
    "        pid, x = titanic_test_np[:, -1], titanic_test_np[:, :-1]\n",
    "        for i in range(len(titanic_test_np)):\n",
    "\n",
    "            feed_dict = {\n",
    "                model.inputs: x[i].reshape(1, 10),\n",
    "                model.keep_prob: 1}\n",
    "\n",
    "            out_val = sess.run(model.output, feed_dict=feed_dict)\n",
    "            fd.write('{},{}\\n'.format(int(pid[i]), int(np.round(out_val)[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
